<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Face-Tracked 3D Window</title>
    <style>
        body { margin: 0; overflow: hidden; background-color: #222; display: flex; justify-content: center; align-items: center; height: 100vh; }
        canvas { display: block; }
        /* Hide the video element used by MediaPipe */
        .input_video { display: none; }
        .container { position: relative; width: 100%; height: 100%; }
        #output_canvas { position: absolute; top: 0; left: 0; width: 100%; height: 100%; z-index: 1; } /* Ensure 3D canvas is behind debug */
        #debug_canvas {
            position: absolute;
            top: 10px;
            left: 10px;
            width: 320px; /* Smaller debug view */
            height: 240px;
            border: 1px solid white;
            z-index: 2; /* Ensure debug canvas is on top */
        }
        .controls {
            position: absolute;
            bottom: 20px;
            left: 50%;
            transform: translateX(-50%);
            background-color: rgba(0, 0, 0, 0.5);
            padding: 10px;
            border-radius: 5px;
            z-index: 3;
            display: flex;
            gap: 10px;
        }
        .controls button {
            padding: 8px 15px;
            cursor: pointer;
        }
        .controls span {
            color: white;
            font-family: sans-serif;
            font-size: 14px;
            align-self: center;
        }
    </style>
    <!-- THREE.js via CDN -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <!-- MediaPipe FaceMesh and Camera Utils via CDN -->
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js" crossorigin="anonymous"></script> <!-- Optional: for debugging landmarks -->
</head>
<body>
    <div class="container">
        <video class="input_video" playsinline muted></video>
        <canvas id="output_canvas"></canvas>
        <canvas id="debug_canvas"></canvas> <!-- Added debug canvas -->
        <div class="controls">
            <button id="setNearBtn">Set Near Point</button>
            <button id="setFarBtn">Set Far Point</button>
            <label style="color:white;font-family:sans-serif;">
              depth&nbsp;
              <input type="range" id="parallaxScale" min="0.2" max="1" step="0.05" value="1">
            </label>
            <span id="calibrationStatus">Status: Not Calibrated</span>
        </div>
    </div>

    <script type="module">
        // --- Configuration ---
        // const MAX_OFFSET = 2.0; // Removed - Replaced by dynamic calculation
        const SMOOTHING = 0.05; // Smoothing factor (0-1, lower is smoother)
        const LEFT_EYE_INDEX = 159; // Lower-mid landmark index for left eye
        const RIGHT_EYE_INDEX = 386; // Lower-mid landmark index for right eye
        const MIN_CAMERA_Z = 3.0; // Camera Z when head is closest
        const MAX_CAMERA_Z = 7.0; // Camera Z when head is furthest
        const INITIAL_CAMERA_Z = 4.0; // Starting Z position (a bit closer)

        // --- Global Variables ---
        let scene, camera, renderer, cube, sphere, torus;
        let targetCameraOffsetX = 0, targetCameraOffsetY = 0, targetCameraOffsetZ = INITIAL_CAMERA_Z;
        let currentCameraOffsetX = 0, currentCameraOffsetY = 0, currentCameraOffsetZ = INITIAL_CAMERA_Z;
        let nearEyeDist = null, farEyeDist = null; // Calibration values
        let lastRawEyeDist = 0; // Store latest eye distance for calibration clicks
        const videoElement = document.getElementsByClassName('input_video')[0];
        const canvasElement = document.getElementById('output_canvas');
        const debugCanvas = document.getElementById('debug_canvas');
        const debugCtx = debugCanvas.getContext('2d');
        const calibrationStatusElement = document.getElementById('calibrationStatus');
        const setNearBtn = document.getElementById('setNearBtn');
        const setFarBtn = document.getElementById('setFarBtn');
        const parallaxScale = document.getElementById('parallaxScale'); // Added slider reference
        // Access drawingUtils from the global scope (loaded via CDN)
        const drawingUtils = window;


        // --- THREE.js Setup ---
        function initThree() {
            scene = new THREE.Scene();
            scene.background = new THREE.Color(0x222222);

            // Camera
            const aspect = window.innerWidth / window.innerHeight;
            camera = new THREE.PerspectiveCamera(75, aspect, 0.1, 1000);
            camera.position.z = INITIAL_CAMERA_Z; // Use constant for initial Z

            // Renderer
            renderer = new THREE.WebGLRenderer({ canvas: canvasElement, antialias: true });
            renderer.setSize(window.innerWidth, window.innerHeight);

            // Lighting
            const ambientLight = new THREE.AmbientLight(0x404040); // Soft white light
            scene.add(ambientLight);
            const directionalLight = new THREE.DirectionalLight(0xffffff, 0.8);
            directionalLight.position.set(1, 1, 1);
            scene.add(directionalLight);

            // Cube (Green, Middle)
            const cubeGeometry = new THREE.BoxGeometry(1, 1, 1);
            const cubeMaterial = new THREE.MeshStandardMaterial({ color: 0x00ff00 });
            cube = new THREE.Mesh(cubeGeometry, cubeMaterial);
            cube.position.set(0, 0, 0); // Center
            scene.add(cube);

            // Sphere (Red, Far)
            const sphereGeometry = new THREE.SphereGeometry(0.75, 32, 32);
            const sphereMaterial = new THREE.MeshStandardMaterial({ color: 0xff0000 });
            sphere = new THREE.Mesh(sphereGeometry, sphereMaterial);
            sphere.position.set(-1.5, 0.5, -3); // Offset and further back
            scene.add(sphere);

            // Torus (Blue, Close)
            const torusGeometry = new THREE.TorusGeometry(0.5, 0.2, 16, 100);
            const torusMaterial = new THREE.MeshStandardMaterial({ color: 0x0000ff });
            torus = new THREE.Mesh(torusGeometry, torusMaterial);
            torus.position.set(1.5, -0.5, 2); // Offset and closer
            scene.add(torus);

            // Handle window resize
            window.addEventListener('resize', onWindowResize, false);

            // Start animation loop
            animate();
        }

        // return {width, height} of the frustum slice at depth z
        function viewSizeAtDepth(z) {
          // Ensure camera is initialized before calling this
          if (!camera) return { width: 0, height: 0 };
          const h = 2 * z * Math.tan(THREE.MathUtils.degToRad(camera.fov * 0.5));
          return { width: h * camera.aspect, height: h };
        }

        // --- MediaPipe FaceMesh Setup ---
        function initMediaPipe() {
            const faceMesh = new FaceMesh({locateFile: (file) => {
                return `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`;
            }});

            faceMesh.setOptions({
                maxNumFaces: 1,
                refineLandmarks: true, // Get iris landmarks if needed later
                minDetectionConfidence: 0.5,
                minTrackingConfidence: 0.5
            });

            faceMesh.onResults(onResults);

            // Use CameraUtils to manage webcam feed
            // Correct constructor: new Camera(videoElement, options)
            const camera = new Camera(videoElement, {
                 onFrame: async () => {
                    // No need to clear canvas if not drawing video/landmarks
                    await faceMesh.send({image: videoElement});
                 },
                 width: 640, // Lower resolution is often sufficient and faster
                 height: 480
            });
            camera.start();
        }

        // --- MediaPipe Results Callback ---
        function onResults(results) {
            // Draw landmarks and video feed onto the debug canvas
            debugCtx.save();
            debugCtx.clearRect(0, 0, debugCanvas.width, debugCanvas.height);
            // Ensure the image is mirrored like the video feed
            debugCtx.translate(debugCanvas.width, 0);
            debugCtx.scale(-1, 1);
            debugCtx.drawImage(results.image, 0, 0, debugCanvas.width, debugCanvas.height);

            if (results.multiFaceLandmarks && results.multiFaceLandmarks.length > 0) {
                const landmarks = results.multiFaceLandmarks[0]; // Use the first detected face

                // Draw the full face mesh
                drawingUtils.drawConnectors(debugCtx, landmarks, FACEMESH_TESSELATION,
                                   {color: '#C0C0C070', lineWidth: 1});
                // Highlight the specific eye landmarks used
                drawingUtils.drawLandmarks(debugCtx, [landmarks[LEFT_EYE_INDEX], landmarks[RIGHT_EYE_INDEX]],
                                  {color: '#FF0000', radius: 3});


                // Get landmarks for the center of the lower eyelid
                const leftEye = landmarks[LEFT_EYE_INDEX];
                const rightEye = landmarks[RIGHT_EYE_INDEX];

                if (leftEye && rightEye) {
                    // Calculate the midpoint (barycenter) between the eyes
                    const eyeCenterX = (leftEye.x + rightEye.x) / 2;
                    const eyeCenterY = (leftEye.y + rightEye.y) / 2;

                    // Convert normalized screen coordinates (0-1) to centered coordinates (-0.5 to 0.5)
                    // Invert Y because screen Y is top-down, but 3D Y is bottom-up
                    const normalizedX = eyeCenterX - 0.5;
                    const normalizedY = -(eyeCenterY - 0.5);

                    // --- X/Y Offset Calculation (physical) ---
                    // Use current smoothed Z for stable view size calculation
                    const { width: vw, height: vh } = viewSizeAtDepth(currentCameraOffsetZ);
                    // move exactly half a frustum so the scene edge aligns with screen edge at max head move
                    targetCameraOffsetX = normalizedX * (vw * 0.5);
                    targetCameraOffsetY = normalizedY * (vh * 0.5);

                    // Apply parallax scale from slider
                    const scale = parseFloat(parallaxScale.value);
                    targetCameraOffsetX *= scale;
                    targetCameraOffsetY *= scale;


                    // --- Z Offset (Depth) Calculation ---
                    // Calculate raw distance between eyes in normalized coords
                    const dx = leftEye.x - rightEye.x;
                    const dy = leftEye.y - rightEye.y;
                    // Use image width to make distance somewhat consistent across resolutions
                    lastRawEyeDist = Math.hypot(dx * results.image.width, dy * results.image.height);

                    // Map eye distance to camera Z if calibrated
                    if (nearEyeDist !== null && farEyeDist !== null && nearEyeDist > farEyeDist) {
                        // Clamp current distance to the calibrated range
                        const clampedEyeDist = Math.max(farEyeDist, Math.min(nearEyeDist, lastRawEyeDist));
                        // Calculate ratio (0 = far, 1 = near)
                        const depthRatio = (clampedEyeDist - farEyeDist) / (nearEyeDist - farEyeDist);
                        // Interpolate camera Z (lerp)
                        // Target Z = MAX_Z when ratio is 0 (far), MIN_Z when ratio is 1 (near)
                        targetCameraOffsetZ = MAX_CAMERA_Z + (MIN_CAMERA_Z - MAX_CAMERA_Z) * depthRatio;
                    } else {
                        // Not calibrated, keep Z fixed at initial position
                        targetCameraOffsetZ = INITIAL_CAMERA_Z;
                    }
                }
            } else {
                // Optional: Reset target offsets if no face is detected
                // targetCameraOffsetX = 0;
                // targetCameraOffsetY = 0;
                // targetCameraOffsetZ = INITIAL_CAMERA_Z; // Reset Z as well?
                // targetCameraOffsetY = 0;
            }
            debugCtx.restore(); // Restore context state
        }

        // --- THREE.js Animation Loop ---
        function animate() {
            requestAnimationFrame(animate);

            // Apply smoothing (Low-pass filter) to X, Y, and Z offsets
            currentCameraOffsetX += (targetCameraOffsetX - currentCameraOffsetX) * SMOOTHING;
            currentCameraOffsetY += (targetCameraOffsetY - currentCameraOffsetY) * SMOOTHING;
            currentCameraOffsetZ += (targetCameraOffsetZ - currentCameraOffsetZ) * SMOOTHING;

            // Update camera position based on smoothed offsets
            camera.position.x = currentCameraOffsetX;
            camera.position.y = currentCameraOffsetY;
            camera.position.z = currentCameraOffsetZ; // Update Z position

            // Always look at the center of the scene
            camera.lookAt(scene.position);

            // Cube rotation removed to achieve the "window" effect
            // cube.rotation.x += 0.01; // Removed
            // cube.rotation.y += 0.01; // Removed

            renderer.render(scene, camera);
        }

        // --- Window Resize Handler ---
        function onWindowResize() {
            camera.aspect = window.innerWidth / window.innerHeight;
            camera.updateProjectionMatrix();
            renderer.setSize(window.innerWidth, window.innerHeight);
        }

        // --- Calibration ---
        function updateCalibrationStatus() {
            if (nearEyeDist !== null && farEyeDist !== null) {
                if (nearEyeDist > farEyeDist) {
                    calibrationStatusElement.textContent = `Status: Calibrated (Near: ${nearEyeDist.toFixed(1)}, Far: ${farEyeDist.toFixed(1)})`;
                    calibrationStatusElement.style.color = 'lightgreen';
                } else {
                    calibrationStatusElement.textContent = 'Status: Error - Near must be > Far. Recalibrate.';
                    calibrationStatusElement.style.color = 'red';
                }
            } else if (nearEyeDist !== null) {
                calibrationStatusElement.textContent = `Status: Near set (${nearEyeDist.toFixed(1)}). Set Far Point.`;
                calibrationStatusElement.style.color = 'yellow';
            } else if (farEyeDist !== null) {
                calibrationStatusElement.textContent = `Status: Far set (${farEyeDist.toFixed(1)}). Set Near Point.`;
                calibrationStatusElement.style.color = 'yellow';
            } else {
                calibrationStatusElement.textContent = 'Status: Not Calibrated';
                calibrationStatusElement.style.color = 'white';
            }
        }

        setNearBtn.addEventListener('click', () => {
            if (lastRawEyeDist > 0) {
                nearEyeDist = lastRawEyeDist;
                console.log(`Set Near Point - Eye Distance: ${nearEyeDist}`);
                updateCalibrationStatus();
            } else {
                console.warn("Cannot set Near Point: No face detected or eye distance is zero.");
            }
        });

        setFarBtn.addEventListener('click', () => {
            if (lastRawEyeDist > 0) {
                farEyeDist = lastRawEyeDist;
                console.log(`Set Far Point - Eye Distance: ${farEyeDist}`);
                updateCalibrationStatus();
            } else {
                console.warn("Cannot set Far Point: No face detected or eye distance is zero.");
            }
        });


        // --- Initialization ---
        initThree();
        initMediaPipe();
        updateCalibrationStatus(); // Set initial status message

    </script>
</body>
</html>
